{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3OO6Zl9dojat"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os,gc\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from scipy.stats import chi2_contingency, chisquare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dy15MLXM3nWN"
      },
      "outputs": [],
      "source": [
        "TRAIN_FEATURES_PATH = \"kaggle/datafest/data/train_data_fe/\"\n",
        "TEST_FEATURES_PATH = \"kaggle/datafest/data/test_data_fe/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3atewf7ro0aD",
        "outputId": "5712906c-15a5-4561-fb52-833434d34855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LQskfpQeo5hy"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n"
      ],
      "metadata": {
        "id": "Iwu_RitHbgxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_6itezyIq54",
        "outputId": "dd7a43fa-c62f-4263-bb1d-74efff227fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of positive class 0.04\n"
          ]
        }
      ],
      "source": [
        "# target variable\n",
        "\n",
        "train_target = pd.read_csv('kaggle/datafest/data/train_target.csv')\n",
        "\n",
        "print(f\"Proportion of positive class {np.round((train_target['flag'] == 1).mean(), 2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mZgntW9AD5W",
        "outputId": "646283d5-6b57-4101-f6e2-e46d06b5fffd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# check the shape of train dataframes\n",
        "\n",
        "all_trains = list()\n",
        "number_of_features = 450\n",
        "nums = [num for num in range(12)]\n",
        "for num in nums:\n",
        "  train = pd.read_parquet(TRAIN_FEATURES_PATH + f\"train_fe_{num}.pq\")\n",
        "  assert train.shape[1] == number_of_features, f\"Train part {num} has \\\n",
        "                                                 different number of features\"\n",
        "  all_trains.append(train)\n",
        "\n",
        "del train, nums\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAcTtesEA8eQ",
        "outputId": "c4b80314-e5d2-48fd-e0fb-fcf09dfc89c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# check the shape of test dataframes\n",
        "\n",
        "all_tests = list()\n",
        "nums = [num for num in range(2)]\n",
        "for num in nums:\n",
        "  test = pd.read_parquet(TEST_FEATURES_PATH + f\"test_fe_{num}.pq\")\n",
        "  assert test.shape[1] == number_of_features, f\"Test part {num} has \\\n",
        "                                                 different number of features\"\n",
        "  all_tests.append(test)\n",
        "  \n",
        "del test, nums, number_of_features\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPKJubS0DMCX",
        "outputId": "350df6b9-7c3e-4098-edfb-9ae96e63aa24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whole test shape: (500000, 450)\n",
            "\n",
            "Whole train shape: (3000000, 450)\n"
          ]
        }
      ],
      "source": [
        "# concat the test set\n",
        "whole_test = pd.concat(all_tests)\n",
        "\n",
        "# concat the train set\n",
        "whole_train = pd.concat(all_trains)\n",
        "\n",
        "del all_tests, all_trains\n",
        "gc.collect()\n",
        "\n",
        "print(f\"Whole test shape: {whole_test.shape}\\n\")\n",
        "print(f\"Whole train shape: {whole_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMaRnq-VkEbv"
      },
      "source": [
        "Check the dependence of each feature with target variable:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B4nazugrkKIR"
      },
      "outputs": [],
      "source": [
        "def chi2_feature_selection(dataframe: pd.DataFrame, cat_features: list,\n",
        "                           target: np.array, alpha: float) -> list:\n",
        "    \"\"\"\n",
        "    The function determines independent features from the target variable.\n",
        "\n",
        "    H0 - feature and target variable are independent(feature is not important)\n",
        "    H1 - feature and target variable are dependent(feature is important)\n",
        "    \n",
        "    :param dataframe: pd.DataFrame to select the features\n",
        "    :param cat_features: list of categorical features\n",
        "    :param target: np.array target variable\n",
        "    :param alpha: significant level\n",
        "    :return: list of features which are independent from the target variable\n",
        "    \"\"\"\n",
        "    unimportant_cols = []\n",
        "    for col in cat_features:\n",
        "      data = pd.crosstab(dataframe[col], target)\n",
        "      stat, p, dof, expected = chi2_contingency(data)\n",
        "      if p > alpha: # Variables are independent (fail to reject H0)\n",
        "        unimportant_cols.append(col)\n",
        "\n",
        "      del data, stat, p, dof, expected\n",
        "    gc.collect()\n",
        "    print(f\"There are(is) {len(unimportant_cols)} unimportant cols.\")\n",
        "\n",
        "    return unimportant_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj1iEHwLkLkv",
        "outputId": "da7298b9-0198-4585-aff2-c6ee3795d01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are(is) 31 unimportant cols.\n"
          ]
        }
      ],
      "source": [
        "# find independent features from the target variable\n",
        "\n",
        "cols_to_del = chi2_feature_selection(whole_train, whole_train.columns,\n",
        "                                     train_target['flag'], 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WGDU54lm6M10"
      },
      "outputs": [],
      "source": [
        "# drop these features\n",
        "\n",
        "whole_train.drop(cols_to_del, axis=1, inplace=True)\n",
        "whole_test.drop(cols_to_del, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXnAJZgutZFc",
        "outputId": "0e10cb0e-3237-404c-ecfa-fd587b579007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finally we have 419 features.\n"
          ]
        }
      ],
      "source": [
        "# define the features to train the models\n",
        "\n",
        "FTS = whole_train.columns\n",
        "\n",
        "del cols_to_del, chi2_feature_selection\n",
        "gc.collect()\n",
        "\n",
        "print(f\"Finally we have {len(FTS)} features.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hah8AZOsBhdi"
      },
      "source": [
        "## Modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chi2_model_eval(data: np.array, alpha: float) -> None:\n",
        "    \"\"\"\n",
        "    The function calculates whether model is random guesser or not.\n",
        "\n",
        "      H0 - variables in contingency table are independent \n",
        "           (model is a random guesser)\n",
        "      H1 - variables in contingency table are dependent\n",
        "           (model is not a random guesser)\n",
        "\n",
        "    :param data: model's confusion matrix\n",
        "    :param alpha: significant level\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    stat, p, dof, expected = chi2_contingency(data)\n",
        "    print(f\"Chi-square statistic = {stat}\")\n",
        "    print(f\"P-value = {p}\")\n",
        "    print(f\"Alpha = {alpha}\")\n",
        "\n",
        "    if p < alpha:\n",
        "        print('\\nModel is Not a random guesser (reject H0).')\n",
        "    else:\n",
        "        print('\\nModel ia a random guesser (fail to reject H0).')"
      ],
      "metadata": {
        "id": "9PkM3eb9aN6n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WCe-Cxz5N7XU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1a64c5-a1fd-4459-b5e6-8b12226574c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score is 0.7634491622447968\n",
            "\n",
            "Checking if a model is a random guesser.\n",
            "\n",
            "Chi-square statistic = 13240.687246181918\n",
            "P-value = 0.0\n",
            "Alpha = 0.05\n",
            "\n",
            "Model is Not a random guesser (reject H0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score is 0.7659362256526947\n",
            "\n",
            "Checking if a model is a random guesser.\n",
            "\n",
            "Chi-square statistic = 13487.165824821632\n",
            "P-value = 0.0\n",
            "Alpha = 0.05\n",
            "\n",
            "Model is Not a random guesser (reject H0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score is 0.7625938057899475\n",
            "\n",
            "Checking if a model is a random guesser.\n",
            "\n",
            "Chi-square statistic = 12991.855103903044\n",
            "P-value = 0.0\n",
            "Alpha = 0.05\n",
            "\n",
            "Model is Not a random guesser (reject H0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score is 0.7611766755580902\n",
            "\n",
            "Checking if a model is a random guesser.\n",
            "\n",
            "Chi-square statistic = 12645.048874905262\n",
            "P-value = 0.0\n",
            "Alpha = 0.05\n",
            "\n",
            "Model is Not a random guesser (reject H0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score is 0.7655340433120728\n",
            "\n",
            "Checking if a model is a random guesser.\n",
            "\n",
            "Chi-square statistic = 13664.572574473237\n",
            "P-value = 0.0\n",
            "Alpha = 0.05\n",
            "\n",
            "Model is Not a random guesser (reject H0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because AUC is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score is 0.7615915536880493\n",
            "\n",
            "Checking if a model is a random guesser.\n",
            "\n",
            "Chi-square statistic = 13131.777303250652\n",
            "P-value = 0.0\n",
            "Alpha = 0.05\n",
            "\n",
            "Model is Not a random guesser (reject H0).\n"
          ]
        }
      ],
      "source": [
        "X = whole_train[FTS].copy()\n",
        "y = train_target['flag']\n",
        "\n",
        "# number of folds\n",
        "n_splits = 6\n",
        "# cv \n",
        "skf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "# list for classifiers\n",
        "clfs = []\n",
        "\n",
        "# cv training\n",
        "for train_index, val_index in skf.split(X, y):\n",
        "    # split data\n",
        "    X_train = X.iloc[train_index]\n",
        "    X_val = X.iloc[val_index]\n",
        "    y_train = y.iloc[train_index]\n",
        "    y_val = y.iloc[val_index]\n",
        "    del train_index, val_index\n",
        "    # model\n",
        "    clf = CatBoostClassifier(iterations=2000,\n",
        "                             max_depth=8,\n",
        "                             verbose=0,\n",
        "                             eval_metric='AUC',\n",
        "                             early_stopping_rounds=200,\n",
        "                             class_weights=[0.5, 10],\n",
        "                             use_best_model=True,\n",
        "                             task_type='GPU',\n",
        "                             random_state=42)\n",
        "    # train the model\n",
        "    clf.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
        "    # best score on validation\n",
        "    print(f\"Best score is {clf.best_score_['validation']['AUC']}\")\n",
        "    # check if the model is a random guesser\n",
        "    val_prediction = clf.predict(X_val)\n",
        "    conf_matrix = confusion_matrix(y_val, val_prediction)\n",
        "    # test of independence\n",
        "    print(f\"\\nChecking if a model is a random guesser.\")\n",
        "    chi2_model_eval(conf_matrix, 0.05)\n",
        "    # add the model to the list of classifiers\n",
        "    clfs.append(clf)\n",
        "\n",
        "    del X_train, X_val, y_train, y_val, clf, val_prediction, conf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJkpUg3I6zbe",
        "outputId": "d441a5ad-e254-442d-e84d-f0b98706edb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7633802443742753"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# calculate the average score\n",
        "\n",
        "avg_score = 0\n",
        "for model in clfs:\n",
        "  avg_score += model.best_score_['validation']['AUC'] / n_splits\n",
        "\n",
        "avg_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cJFDO_geUUPo"
      },
      "outputs": [],
      "source": [
        "# predict the test\n",
        "\n",
        "oof = np.zeros(shape=whole_test.shape[0])\n",
        "for model in clfs:\n",
        "  oof += model.predict_proba(whole_test[FTS])[:, 1] / len(clfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S0SnUnnrU61w"
      },
      "outputs": [],
      "source": [
        "# create submission df\n",
        "\n",
        "kf_submission = pd.DataFrame({\n",
        "    \"id\" : whole_test.index.values,\n",
        "    \"score\": oof\n",
        "}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4i-yc1KjVFAn"
      },
      "outputs": [],
      "source": [
        "# save submission\n",
        "\n",
        "kf_submission.to_csv('kaggle/datafest/data/kf_submission_00.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HMJ8PK9wVOiA"
      },
      "outputs": [],
      "source": [
        "del oof, kf_submission"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3_prediction.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
