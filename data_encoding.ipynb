{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c7012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695b60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"train_data/\"\n",
    "TEST_DATA_PATH = \"test_data/\"\n",
    "\n",
    "TRAIN_TARGET_PATH = \"train_target.csv\"\n",
    "\n",
    "TRAIN_FE_PATH = 'train_data_fe/'\n",
    "TEST_FE_PATH = 'test_data_fe/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cf1c3",
   "metadata": {},
   "source": [
    "WE USE ONE-HOT ENCODING METHOD FOR DATA ENCODING.\n",
    "\n",
    "FIRST WE FIND A PART WITH THE HIGHEST NUMBER OF UNIQUE VALUES IN ORDER TO PRESERVE ALL THE UNIQUE VALUES, FIT THE ENCODER ON IT  AND THEN TRANSFORM THE REST OF PARTS.\n",
    "\n",
    "AT THE END, WE COUNT THE NUMBER OF TIMES EACH FEATURE IS OCCURRED GROUPPED BY ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6070db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 df has 433 unique values.\n",
      "1 df has 437 unique values.\n",
      "2 df has 436 unique values.\n",
      "3 df has 439 unique values.\n",
      "4 df has 438 unique values.\n",
      "5 df has 442 unique values.\n",
      "6 df has 447 unique values.\n",
      "7 df has 441 unique values.\n",
      "8 df has 446 unique values.\n",
      "9 df has 449 unique values.\n",
      "10 df has 447 unique values.\n",
      "11 df has 448 unique values.\n"
     ]
    }
   ],
   "source": [
    "for num in range(12):\n",
    "    # read the data\n",
    "    data = pd.read_parquet(TRAIN_DATA_PATH + f'train_data_{num}.pq')\n",
    "    # create custom features\n",
    "    # difference between planned number of days from the loan opening date to the closing date and fact\n",
    "    data['pre_term_diff'] = data['pre_pterm'] - data['pre_fterm']\n",
    "    # flag whether loan is closed earlier or later than planned\n",
    "    data['is_closed_earlier_term'] = data['pre_term_diff'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    data['is_closed_later_term'] = data['pre_term_diff'].apply(lambda x: 1 if x < 0 else 0)\n",
    "    # number of unique values \n",
    "    nunique = data.iloc[:, 2:].nunique().sum()\n",
    "    print(f\"{num} df has {nunique} unique values.\")\n",
    "    \n",
    "    del data, nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b5f2e",
   "metadata": {},
   "source": [
    "THE 9TH DF HAS THE HIGHEST NUMBER OF UNIQUE VALUES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa21e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "data9 = pd.read_parquet(TRAIN_DATA_PATH + f'train_data_{9}.pq')\n",
    "# create custom features\n",
    "# difference between planned number of days from the loan opening date to the closing date and fact\n",
    "data9['pre_term_diff'] = data9['pre_pterm'] - data9['pre_fterm']\n",
    "# flag whether loan is closed earlier or later than planned\n",
    "data9['is_closed_earlier_term'] = data9['pre_term_diff'].apply(lambda x: 1 if x > 0 else 0)\n",
    "data9['is_closed_later_term'] = data9['pre_term_diff'].apply(lambda x: 1 if x < 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523ec093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 80.6 ms, total: 2.11 s\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ohe \n",
    "OHE_ENCODER = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "# fit the encoder\n",
    "OHE_ENCODER.fit(data9.iloc[:, 2:])\n",
    "# get the columns names\n",
    "ALL_COLUMNS = ohe_encoder.get_feature_names(data9.iloc[:, 2:].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1185b175",
   "metadata": {},
   "source": [
    "AFTER ONE-HOT ENCODING ALL FEATURES' DTYPES BECOME INT64, SO WE WILL CHANGE THEM BACK TO INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994bb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_encoding(data: pd.DataFrame, fitted_encoder: OneHotEncoder, columns: np.array) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function transforms features to OHE and counts how many times each feature occured groupped by id\n",
    "    \n",
    "    param data: pd.DataFrame to transform\n",
    "    fitted_encoder: OneHotEncoder fitted on part with highest number of unique values\n",
    "    return: pd.DataFrame - transformed data\n",
    "\n",
    "    \"\"\"\n",
    "    ### custom features ###\n",
    "    \n",
    "    # difference between planned number of days from the loan opening date to the closing date and fact\n",
    "    data['pre_term_diff'] = data['pre_pterm'] - data['pre_fterm']\n",
    "    # flag whether loan is closed earlier or later than planned\n",
    "    data['is_closed_earlier_term'] = data['pre_term_diff'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    data['is_closed_later_term'] = data['pre_term_diff'].apply(lambda x: 1 if x < 0 else 0)\n",
    "    \n",
    "    ### ohe ###\n",
    "    \n",
    "    # transform the data\n",
    "    encoded = fitted_encoder.transform(data.iloc[:, 2:])\n",
    "    # one-hot encoder returns float64 dtype, lets'transform it to int8 and create df\n",
    "    data_enc = pd.DataFrame(encoded.astype('int8'), columns=columns)\n",
    "    # concat encodet data with id columns\n",
    "    data_enc = pd.concat([data.iloc[:, 0], data_enc], axis=1)\n",
    "    # count each event(feature) of clients\n",
    "    data_fe = data_enc.groupby('id')[columns].sum()\n",
    "    # count amount of credits of each client\n",
    "    count_rn = data.groupby('id')['rn'].max()\n",
    "    # concat amount of credits to the rest of data\n",
    "    data_fe = pd.concat([data_fe, count_rn], axis=1)\n",
    "    \n",
    "    \n",
    "    return data_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9e02a",
   "metadata": {},
   "source": [
    "ENCODE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d98d58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [09:07<00:00, 45.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# TRAIN FE\n",
    "\n",
    "for num in tqdm(range(12)):\n",
    "    # read the data\n",
    "    train = pd.read_parquet(TRAIN_DATA_PATH + f'train_data_{num}.pq')\n",
    "    # transform the data\n",
    "    train_fe = features_encoding(train, OHE_ENCODER, ALL_COLUMNS)\n",
    "    # save the data\n",
    "    train_fe.to_parquet(TRAIN_FE_PATH + f\"train_fe_{num}.pq\")\n",
    "    \n",
    "    del train, train_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8914425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [01:39<00:00, 49.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# TEST FE\n",
    "\n",
    "for num in tqdm(range(2)):\n",
    "    # read the data\n",
    "    test = pd.read_parquet(TEST_DATA_PATH + f'test_data_{num}.pq')\n",
    "    # transform the data\n",
    "    test_fe = features_encoding(test, OHE_ENCODER, ALL_COLUMNS)\n",
    "    # save the data\n",
    "    test_fe.to_parquet(TEST_FE_PATH + f\"test_fe_{num}.pq\")\n",
    "    \n",
    "    del test, test_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b032bd",
   "metadata": {},
   "source": [
    "FEATURE ENCODING IS DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
