{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c7012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695b60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"train_data/\"\n",
    "TEST_DATA_PATH = \"test_data/\"\n",
    "\n",
    "TRAIN_TARGET_PATH = \"train_target.csv\"\n",
    "\n",
    "TRAIN_FE_PATH = 'train_data_fe/'\n",
    "TEST_FE_PATH = 'test_data_fe/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06852e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function transforms features to OHE and counts number of ones in each new column\n",
    "    \n",
    "    param data: pd.DataFrame to transform\n",
    "    return: pd.DataFrame - transformed data\n",
    "\n",
    "    \"\"\"\n",
    "    ### custom features ###\n",
    "    \n",
    "    # difference between planned number of days from the loan opening date to the closing date and fact\n",
    "    data['pre_term_diff'] = data['pre_pterm'] - data['pre_fterm']\n",
    "    # flag whether loan is closed earlier or later than planned\n",
    "    data['is_closed_earlier_term'] = data['pre_term_diff'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    data['is_closed_later_term'] = data['pre_term_diff'].apply(lambda x: 1 if x < 0 else 0)\n",
    "    \n",
    "    ### ohe ###\n",
    "    \n",
    "    # dataframe feature names\n",
    "    feauture_columns = data.columns.values[2:]\n",
    "    # get dummies\n",
    "    dummies = pd.get_dummies(data[feauture_columns], columns=feauture_columns)\n",
    "    # concat dummies with id and rn columns\n",
    "    ohe_features = pd.concat([data.iloc[:, :2], dummies], axis=1)\n",
    "    # count how many times client has 1 in each column\n",
    "    data_fe = ohe_features.groupby(\"id\")[dummies.columns.values].sum()\n",
    "    # count amount of credits of each client\n",
    "    count_rn = data.groupby('id')['rn'].max()\n",
    "    # concat amount of credits to the rest of data\n",
    "    data_fe = pd.concat([data_fe, count_rn], axis=1)\n",
    "    \n",
    "    \n",
    "    return data_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d98d58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [25:25<02:18, 138.71s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.18 GiB for an array with shape (2450630, 448) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SN_ELI~1\\AppData\\Local\\Temp/ipykernel_4396/3752996443.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_DATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf'train_data_{num}.pq'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# transform the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_fe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m# save the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_fe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_FE_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf\"train_fe_{num}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SN_ELI~1\\AppData\\Local\\Temp/ipykernel_4396/412726896.py\u001b[0m in \u001b[0;36mfeature_engineering\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mohe_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummies\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# count how many times client has 1 in each column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mdata_fe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohe_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;31m# count amount of credits of each client\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mcount_rn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rn'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;31m# _agg_general() returns. GH #31422\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemp_setattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"observed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m             result = self._agg_general(\n\u001b[0m\u001b[0;32m   1850\u001b[0m                 \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m                 \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_agg_general\u001b[1;34m(self, numeric_only, min_count, alias, npfunc)\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mgroup_selection_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m             \u001b[1;31m# try a cython aggregation if we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m             result = self._cython_agg_general(\n\u001b[0m\u001b[0;32m   1365\u001b[0m                 \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                 \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnpfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1080\u001b[0m         \u001b[1;31m# TypeError -> we may have an exception in trying to aggregate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m         \u001b[1;31m#  continue and exclude the block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mnew_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mgrouped_reduce\u001b[1;34m(self, func, ignore_failures)\u001b[0m\n\u001b[0;32m   1241\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1243\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1244\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \"\"\"\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split_op_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36marray_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0marray_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m                 result = self.grouper._cython_operation(\n\u001b[0m\u001b[0;32m   1069\u001b[0m                     \u001b[1;34m\"aggregate\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                 )\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m         return cy_op.cython_operation(\n\u001b[0m\u001b[0;32m   1000\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mcython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m             )\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m         return self._cython_op_ndim_compat(\n\u001b[0m\u001b[0;32m    661\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         return self._call_cython_op(\n\u001b[0m\u001b[0;32m    517\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mout_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cython_func_and_vals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[0mout_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_out_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mget_cython_func_and_vals\u001b[1;34m(self, values, is_numeric)\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"add\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"var\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"prod\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ohlc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;31m# result may still include NaN, so we have to cast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_float64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\algos_common_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.algos.ensure_float64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.18 GiB for an array with shape (2450630, 448) and data type float64"
     ]
    }
   ],
   "source": [
    "# TRAIN FE\n",
    "\n",
    "for num in tqdm(range(12)):\n",
    "    # read the data\n",
    "    train = pd.read_parquet(TRAIN_DATA_PATH + f'train_data_{num}.pq')\n",
    "    # transform the data\n",
    "    train_fe = feature_engineering(train)\n",
    "    # save the data\n",
    "    train_fe.to_csv(TRAIN_FE_PATH + f\"train_fe_{num}\")\n",
    "    \n",
    "    del train, train_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec5920",
   "metadata": {},
   "source": [
    "WE DO NOT HAVE ENOUGH MEMORY FOR 11TH PART LET'S CHECK ITS & TEST'S SHAPE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377f4eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2450630, 61), (2389773, 61), (2334828, 61))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "train_11 = pd.read_parquet(TRAIN_DATA_PATH + f'train_data_11.pq')\n",
    "test_0 = pd.read_parquet(TEST_DATA_PATH + f'test_data_0.pq')\n",
    "test_1 = pd.read_parquet(TEST_DATA_PATH + f'test_data_1.pq')\n",
    "\n",
    "# shape of data\n",
    "train_11.shape, test_0.shape, test_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed40fc",
   "metadata": {},
   "source": [
    "WE SEE THAT BOTH OF 3 DATAFRAMES HAVE SIMILAR SHAPE\n",
    "\n",
    "SPLIT THEM ALL TO 2 PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a96fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Split the data to 2 parts\n",
    "    \n",
    "    param: data - pd.DataFrame of data to split\n",
    "    \n",
    "    \"\"\"\n",
    "    # middle index of data\n",
    "    middle_idx = np.round(len(data) / 2)\n",
    "    # id of the middle index of data\n",
    "    middle_idx_id = data.loc[middle_idx, 'id']\n",
    "    # splt data by id\n",
    "    data_1 = data[data['id'] <= middle_idx_id]\n",
    "    data_2 = data[data['id'] > middle_idx_id]\n",
    "    \n",
    "    return data_1, data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c015e066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1225324, 61), (1225306, 61))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "train_11_0, train_11_1 = split_data(train_11)\n",
    "train_11_0.shape, train_11_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54906bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1194889, 61), (1194884, 61), (1167428, 61), (1167400, 61))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "test_0_0, test_0_1 = split_data(test_0)\n",
    "test_1_0, test_1_1 = split_data(test_1)\n",
    "\n",
    "test_0_0.shape, test_0_1.shape, test_1_0.shape, test_1_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1090dbab",
   "metadata": {},
   "source": [
    "FINISH THE FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a52b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SN_ELI~1\\AppData\\Local\\Temp/ipykernel_11648/412726896.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['pre_term_diff'] = data['pre_pterm'] - data['pre_fterm']\n",
      "C:\\Users\\SN_ELI~1\\AppData\\Local\\Temp/ipykernel_11648/412726896.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['is_closed_earlier_term'] = data['pre_term_diff'].apply(lambda x: 1 if x > 0 else 0)\n",
      "C:\\Users\\SN_ELI~1\\AppData\\Local\\Temp/ipykernel_11648/412726896.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['is_closed_later_term'] = data['pre_term_diff'].apply(lambda x: 1 if x < 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "# transform the data\n",
    "train_11_0_fe = feature_engineering(train_11_0)\n",
    "train_11_1_fe = feature_engineering(train_11_1)\n",
    "test_0_0_fe = feature_engineering(test_0_0)\n",
    "test_0_1_fe = feature_engineering(test_0_1)\n",
    "test_1_0_fe = feature_engineering(test_1_0)\n",
    "test_1_1_fe = feature_engineering(test_1_1)\n",
    "\n",
    "# save the data\n",
    "train_11_0_fe.to_csv(TRAIN_FE_PATH + \"train_fe_11_0\")\n",
    "train_11_1_fe.to_csv(TRAIN_FE_PATH + \"train_fe_11_1\")\n",
    "test_0_0_fe.to_csv(TEST_FE_PATH + \"test_fe_0_0\")\n",
    "test_0_1_fe.to_csv(TEST_FE_PATH + \"test_fe_0_1\")\n",
    "test_1_0_fe.to_csv(TEST_FE_PATH + \"test_fe_1_0\")\n",
    "test_1_1_fe.to_csv(TEST_FE_PATH + \"test_fe_1_1\")\n",
    "\n",
    "del train_11_0, train_11_1\n",
    "del test_0_0, test_0_1, test_1_0, test_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895991dc",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING IS DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
